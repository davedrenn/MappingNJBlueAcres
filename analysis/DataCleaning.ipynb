{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bce08840-2907-42d0-b62f-cb6923938d43",
   "metadata": {},
   "source": [
    "---\n",
    "format: \n",
    "  html:\n",
    "    toc: false\n",
    "    page-layout: full\n",
    "    code-fold: true\n",
    "    code-tools: true\n",
    "execute:\n",
    "    echo: true\n",
    "    warning: false\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac22a4ea-f842-4266-abca-2598a9876238",
   "metadata": {},
   "source": [
    "# 2) NFIP Data Processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d82978-6e6e-460f-8466-ccd2c1cfb4c1",
   "metadata": {},
   "source": [
    "FEMA administers the National Flood Insurance Program (NFIP), which helps to identify flood risks, support floodplain management, and provide flood insurance and protection. The OpenFEMA data portal provides access to an Federal Insurance and Mitigation Administration (FIMA) [NFIP Redacted Claims data set](https://www.fema.gov/openfema-data-page/fima-nfip-redacted-claims-v2). This data set has over 2 million records, with personally identifying information removed and latitude/longitude coordinates simplified to one decimal. Due to challenges with accessing the data through FEMA's API and being unable to host the file on GitHub due to file size, the data was instead downloaded locally, cleaned, and resaved to a smaller version available in this projects repository.\n",
    "\n",
    "Cleaning steps included extracting latituden and longitude coordinates, then filtering for New Jersey claims between 1995 and 2023, with the latter date chosen since it aligns with the start of the Blue Acres program. Additionally, only single family home claims were included in this cleaned data set, since only private property is eligble for buyouts and the Blue Acres program has focused on homeowners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6907d6d-1523-43aa-9e0e-a3c5c08c6edd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "\n",
    "# packages\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# options\n",
    "pd.options.display.max_columns = 999\n",
    "\n",
    "# load data (not available in repo, file too large - download here: https://www.fema.gov/openfema-data-page/fima-nfip-redacted-claims-v2 \n",
    "claims_df = pd.read_csv(\"data/claims.csv\")\n",
    "\n",
    "claims_features= claims_df.loc[:, (\"dateOfLoss\", \n",
    "                          \"baseFloodElevation\", \n",
    "                          \"ratedFloodZone\", \n",
    "                          \"locationOfContents\", \n",
    "                          \"occupancyType\", \n",
    "                          \"amountPaidOnBuildingClaim\",\n",
    "                          \"amountPaidOnContentsClaim\",\n",
    "                          \"totalBuildingInsuranceCoverage\",\n",
    "                          \"totalContentsInsuranceCoverage\",\n",
    "                          \"yearOfLoss\",\n",
    "                          \"primaryResidenceIndicator\",\n",
    "                          \"buildingDamageAmount\", \n",
    "                          \"netBuildingPaymentAmount\",\n",
    "                          \"buildingPropertyValue\",\n",
    "                          \"contentsDamageAmount\",\n",
    "                          \"netContentsPaymentAmount\",\n",
    "                          \"contentsPropertyValue\",\n",
    "                          \"floodCharacteristicsIndicator\",\n",
    "                          \"floodWaterDuration\",\n",
    "                          \"floodproofedIndicator\",\n",
    "                          \"floodEvent\",\n",
    "                          \"buildingReplacementCost\",\n",
    "                          \"contentsReplacementCost\",\n",
    "                          \"stateOwnedIndicator\",\n",
    "                          \"buildingDescriptionCode\",\n",
    "                          \"rentalPropertyIndicator\",\n",
    "                          \"state\",\n",
    "                          \"countyCode\",\n",
    "                          \"censusTract\",\n",
    "                          \"censusBlockGroupFips\",\n",
    "                          \"latitude\",\n",
    "                          \"longitude\",\n",
    "                          \"id\")]\n",
    "\n",
    "# fix number formatting, have to repeat again when loading into a different notebook\n",
    "claims_features['countyCode'] = claims_features['countyCode'].astype(str).str.rstrip('.0')\n",
    "claims_features['censusTract'] = claims_features['censusTract'].astype(str).str.rstrip('.0')\n",
    "claims_features['censusBlockGroupFips'] = claims_features['censusBlockGroupFips'].astype(str).str.rstrip('.0')\n",
    "\n",
    "# Remove rows with missing geometry\n",
    "claims_features = claims_features.dropna(subset=[\"latitude\", \"longitude\"])\n",
    "\n",
    "# Create geoDataFrame\n",
    "claims = gpd.GeoDataFrame(\n",
    "    claims_features,\n",
    "    geometry=gpd.points_from_xy(claims_df[\"longitude\"], claims_df[\"latitude\"]),\n",
    "    crs=\"EPSG:4326\",\n",
    ")\n",
    "\n",
    "# projected coordinate\n",
    "claims_gpd = claims.to_crs('EPSG:3857')\n",
    "\n",
    "# extract lat and lon\n",
    "claims_gpd['x'] = claims_gpd['geometry'].x\n",
    "claims_gpd['y'] = claims_gpd['geometry'].y\n",
    "\n",
    "# filtering for NJ claims since 1995\n",
    "states = ['NJ']\n",
    "claims_NJ = claims_gpd[(claims_gpd['yearOfLoss'] >= 1995) & (claims_gpd['state'].isin(states))]\n",
    "\n",
    "# save all NJ claims\n",
    "from pathlib import Path  \n",
    "filepath = Path('data/claims_NJ.csv')  \n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "claims_NJ.to_csv(filepath) \n",
    "\n",
    "# cleaned claims add sfh parameter, claims_sfh creates separate df for them\n",
    "claims_NJ_clean=claims_NJ\n",
    "sfh = (claims_NJ_clean['occupancyType'] == 1) | (claims_NJ_clean['occupancyType'] == 11)\n",
    "claims_NJ_clean['sfh'] = np.where(sfh, 1, 0)\n",
    "claims_NJ_clean['observation'] = 1\n",
    "claims_sfh = claims_NJ_clean[claims_NJ_clean['sfh'] == 1]\n",
    "\n",
    "# save cleaned NJ claims\n",
    "from pathlib import Path  \n",
    "filepath = Path('data/claims_NJ_clean.csv')  \n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "claims_NJ_clean.to_csv(filepath) \n",
    "\n",
    "# save single family housing NJ claims\n",
    "from pathlib import Path  \n",
    "filepath = Path('data/claims_sfh.csv')  \n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "claims_sfh.to_csv(filepath) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
