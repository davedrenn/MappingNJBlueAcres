[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Mapping the NJ Blue Acres Program and NFIP Claims",
    "section": "",
    "text": "This project was created by Dave Drennan, a graduate student in the University of Pennsylvania’s Master of Urban Spatial Analytics Program. Dave is not affiliated with either the State of New Jersey Department of Environmental Protection (DEP) or the Federal Emergency Management Agency (FEMA). This project was created as a final project for two classes - ENVS6611 and MUSA5500 for Fall 2023.\nThis project is an exploratory analysis of both the New Jersey Blue Acres Program and FEMA’s National Flood Insurance Program (NFIP) Redacted Claims data. Additional demographic data is included from the US Census Bureau. The purpose of this analysis is to examine floodprone areas and where mitigation has happened, either through methods of managed retreat or insurance claims. An overview of the Blue Acres Program is provided on page 1, with pages 2, 3, and 4 analyzing the NFIP data before bringing back in the Blue Acres data. Two clustering algorithms are used - DBSCAN for the Blue Acres data and k-means clustering for the NFIP data. Ultimately, the goal of this project is to fill the gap in data visualization and analysis for the Blue Acres Program and NFIP data in New Jersey and examine the spatial and demographic contexts for both."
  },
  {
    "objectID": "index.html#project-overview",
    "href": "index.html#project-overview",
    "title": "Mapping the NJ Blue Acres Program and NFIP Claims",
    "section": "",
    "text": "This project was created by Dave Drennan, a graduate student in the University of Pennsylvania’s Master of Urban Spatial Analytics Program. Dave is not affiliated with either the State of New Jersey Department of Environmental Protection (DEP) or the Federal Emergency Management Agency (FEMA). This project was created as a final project for two classes - ENVS6611 and MUSA5500 for Fall 2023.\nThis project is an exploratory analysis of both the New Jersey Blue Acres Program and FEMA’s National Flood Insurance Program (NFIP) Redacted Claims data. Additional demographic data is included from the US Census Bureau. The purpose of this analysis is to examine floodprone areas and where mitigation has happened, either through methods of managed retreat or insurance claims. An overview of the Blue Acres Program is provided on page 1, with pages 2, 3, and 4 analyzing the NFIP data before bringing back in the Blue Acres data. Two clustering algorithms are used - DBSCAN for the Blue Acres data and k-means clustering for the NFIP data. Ultimately, the goal of this project is to fill the gap in data visualization and analysis for the Blue Acres Program and NFIP data in New Jersey and examine the spatial and demographic contexts for both."
  },
  {
    "objectID": "index.html#find-out-more",
    "href": "index.html#find-out-more",
    "title": "Mapping the NJ Blue Acres Program and NFIP Claims",
    "section": "Find out more",
    "text": "Find out more\nThe code for this repository is here: https://github.com/davedrenn/MappingNJBlueAcres."
  },
  {
    "objectID": "analysis/DataExploration.html",
    "href": "analysis/DataExploration.html",
    "title": "3) NFIP Claims Data",
    "section": "",
    "text": "Single family home NFIP claims for New Jersey between 1995 and 2023 are visualized to examine trends in the data.\n\n\nCode\n# packages\nimport geopandas as gpd\nimport hvplot.pandas\nimport hvplot\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nimport pygris\nimport datetime as dt\n\n# options\npd.options.display.max_columns = 999\npd.options.display.max_rows = 999\npd.options.display.float_format = '{:.2f}'.format\n\n\nThis data comes from the NFIP redacted claims data set that was filtered for New Jersey, as descibed on the NFIP Data Processing page. New Jersey county boundaries are downloaded using the pygris package for visualization at the end of this data exploration.\n\n\nCode\n# read in data - CLAIMS_NJ IS CLEANED SFH DATA \nclaims_NJ = pd.read_csv(\"data/claims_sfh.csv\")\n# convert admin numbers to strings for compatibility with other datasets\nclaims_NJ['countyCode'] = claims_NJ['countyCode'].astype(str).str.rstrip('.0')\nclaims_NJ['censusTract'] = claims_NJ['censusTract'].astype(str).str.rstrip('.0')\nclaims_NJ['censusBlockGroupFips'] = claims_NJ['censusBlockGroupFips'].astype(str).str.rstrip('.0')\n# convert string of year to datetime year for plotting\nclaims_NJ['yearOfLoss'] = pd.to_datetime(claims_NJ['yearOfLoss'], format='%Y').dt.year\n\n# download administrative boundaries for mapping from pygris\nNJ_counties = pygris.counties(state=\"NJ\", year=2019)\n\n\n\nTotal Claims Per Year (Single Family Houses)\nAfter summing the data by the year that a claim was filed, this line graph shows total single family home NFIP claims per year since 1995. Hurricane Sandy cause the massive spike in 2012, and every other year is a fraction of 2012’s total.\n\n\nCode\n# sums each column of NJ claims for sfh by year of claim\nclaims_sum = claims_NJ.groupby(\"yearOfLoss\").sum(numeric_only = True).reset_index()\n\n# line plot of count of claims\nf, ax= plt.subplots(figsize=(10, 6))\n\nsns.lineplot(\n    x='yearOfLoss', \n    y='observation', \n    data=claims_sum,\n    color=\"darkblue\",\n    ax=ax\n)\n\nax.set_title('SFH Claims Per Year')\nax.set_xlabel('Year')\nax.set_ylabel('Count')\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\n\n\n\n\n\n\n\nAverage Building Damage Per Claim (Single Family Houses)\nThe data is then summarized by the average home damage reported on the NFIP claim per year. Another large spike from Hurricane Sandy appears in 2012, although this graph shows other jumps such as from Hurricane Irene in 2021. While this graph shows damage claims appear to be growing on average since 2004, that average increase may also reflect inflation.\n\n\nCode\n# average each column of NJ claims for sfh by year of claim\nclaims_avg = claims_NJ.groupby(\"yearOfLoss\").mean(numeric_only = True).reset_index()\n\n# line plot of average building damage per claim\nf, ax= plt.subplots(figsize=(10, 6))\n\nsns.lineplot(\n    x='yearOfLoss', \n    y='buildingDamageAmount', \n    data=claims_avg,\n    color=\"darkblue\",\n    ax=ax \n)\n\nax.set_title('Average SFH Damage Claim by Year')\nax.set_xlabel('Year')\nax.set_ylabel('Dollars')\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\n\n\n\n\n\nThe following interactive map visualized number of claims per year since 1995 - a slider is available on the right to change the visible year. Only counties with claims in a given year appear.\nWhile counties across the state have been hit hard and had the most claims in different years, Ocean County appears to have the highest number of annual claims most often.\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nThe following map inconsistently renders to the website, but loads in a Jupyter notebook - investigating underlying issue.\n\n\n\n\nCode\n# Groups by county and year and sums by observations (claims) \nclaims_by_county = claims_NJ.groupby([\"countyCode\", \"yearOfLoss\"]).sum('observation').reset_index()\n# Renames columns for plot\nclaims_by_county = claims_by_county.rename(columns={\"yearOfLoss\" : \"Year\", \"observation\": \"Claims\"})\n\n# Joins claims data with pygris data and creates gdf\nNJ_counties_join = gpd.GeoDataFrame(\n    NJ_counties.merge(\n        claims_by_county,\n        left_on=[\"GEOID\"],\n        right_on=[\"countyCode\"],\n        how=\"left\" \n    ),\n    geometry=\"geometry\"\n)\n\n# Plots claims by county by year\nNJmap = NJ_counties_join.hvplot(\n    c=\"Claims\",\n    groupby = \"Year\",\n    geo=True,\n    cmap=\"viridis\",\n    tiles = \"CartoLight\",\n    alpha = .3,\n    hover_cols = [\"NAME\"],\n    xaxis = None,\n    yaxis = None,\n    frame_height=450,\n    frame_width=600,\n)\n\nNJmap.opts(toolbar=\"above\")"
  },
  {
    "objectID": "analysis/ClaimsKmeans.html",
    "href": "analysis/ClaimsKmeans.html",
    "title": "4) Clustering by Features",
    "section": "",
    "text": "Using the NJ NFIP single family home claims data in conjunction with US Census Bureau American Community Survey (ACS) data, the k-means clustering analyis is used to identify tracts with similar features and label these clusters based on their similar characteristics.\n\n\nCode\n# packages\nimport geopandas as gpd\nimport holoviews as hv\nimport hvplot.pandas\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nimport cenpy\nimport pygris\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import MinMaxScaler, RobustScaler\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\n\n# options\npd.options.display.max_columns = 999\npd.options.display.max_rows = 999\npd.options.display.float_format = '{:.2f}'.format\n\n\nThis data comes from the NFIP redacted claims data set that was filtered for New Jersey, as descibed on the NFIP Data Processing page. New Jersey tracts boundaries are downloaded using the pygris package.\nBecause ACS 5-year estimates are used for economic and demographic characteristics and Census tract geography may change every 10 years when a new Census occurs, single family homes claims data is filtered to include claims between 2010 and 2014. This data was chosen due to the high number of claims that occured in time period from both Hurricane Irene and Hurricane Sandy while matching a range for the ACS 5-year estimates.\n\n\nCode\n# reads data and does preprocessing steps\nclaims_NJ = pd.read_csv(\"data/claims_sfh.csv\")\nclaims_NJ['countyCode'] = claims_NJ['countyCode'].astype(str).str.rstrip('.0')\nclaims_NJ['censusTract'] = claims_NJ['censusTract'].astype(str).str.rstrip('.0')\nclaims_NJ['censusBlockGroupFips'] = claims_NJ['censusBlockGroupFips'].astype(str).str.rstrip('.0')\nclaims_NJ['yearOfLoss'] = pd.to_datetime(claims_NJ['yearOfLoss'], format='%Y').dt.year\n\nclaims_NJ = claims_NJ[(claims_NJ['yearOfLoss'] &gt;= 2010) & (claims_NJ['yearOfLoss'] &lt;= 2014)] \n\n# download administrative boundaries for mapping from pygris\nNJ_tracts = pygris.tracts(state=\"NJ\", year=2014)\n\n\nClaims are aggregating per Census tracts using the average building damage amount and total property value, as well as the sum of total claims for the Census tract, then joined to the tract information from pygris.\n\n\nCode\n\n# helper functions for aggregating data\nagg_functions = {\n    'buildingDamageAmount': 'mean',\n    'observation': 'sum',\n}\n\n# groups by tract and uses helper functions\nclaims_by_tract = claims_NJ.groupby([\"censusTract\"]).agg(agg_functions).reset_index()\n\n# reduces df to necessary columns \nclaims_by_tract.columns = ['censusTract',\n                           'mean_amountbuildingDamageAmount',\n                           'observation']\n\n# fills in tracts with missing ending 0s (compared length to GEOID and naming conventions)\nclaims_by_tract['censusTract'] = claims_by_tract['censusTract'].astype(str).str.pad(width=11, side='right', fillchar='0')\n\n# joins claims to tracts data\nNJ_tracts_join = claims_by_tract.merge(\n    NJ_tracts,\n    left_on=[\"censusTract\"],\n    right_on=[\"GEOID\"]\n)\n\n\nThe Census API is accessed to acquire 5-year estimate data tied to 2014. Variables of interest include the total population of a tract, the number of residents that are white alone, and the median household income in the past 12 months. The population variables are used to calculate the percentage of white residents per Census tracts - the purpose of using this variable is to identify if there are any demographic trends to claims or areas with a high presence of Blue Acres parcels. The data is then added to a dataframe with claims data (average damage and property value for single family homes claims).\n\n\nCode\n# accesses API for ACS 5yr 2019\nacs = cenpy.remote.APIConnection(\"ACSDT5Y2014\")\n\n# defines variables of interest\nvariables = [\n    \"NAME\",\n    \"B03002_001E\", # Total\n    \"B03002_003E\", # Not Hispanic, White\n    \"B19013_001E\", # Median Household Income in Past 12 Months\n]\n\n# accesses API for Census\nNJ_acs = acs.query(\n    cols=variables,\n    geo_unit=\"tract:*\",\n    geo_filter={\"state\": \"34\", \"county\": \"*\"},\n)\n\n# Concats parts of GEOID\nNJ_acs['GEOID'] = NJ_acs['state'].astype(str) + NJ_acs['county'].astype(str) + NJ_acs['tract'].astype(str)\n\n# Converts values from strings to floats\nfor variable in variables:\n    # Convert all variables EXCEPT for NAME\n    if variable != \"NAME\":\n        NJ_acs[variable] = NJ_acs[variable].astype(float)\n        \n# joins tracts data with ACS data\nNJ_tracts_cluster = NJ_tracts_join.merge(\n    NJ_acs,\n    left_on=[\"censusTract\"],\n    right_on=[\"GEOID\"],\n)\n\n# Renames columns\nNJ_tracts_cluster = NJ_tracts_cluster.rename(\n    columns={\n        \"censusTract\" : \"tractID\",\n        \"B03002_001E\": \"TotalPop\", \n        \"B03002_003E\": \"WhiteAlone\",  \n        \"B19013_001E\": \"MedInc\",  \n    }\n)\n\n# Calculates percent of population that's white alone\nNJ_tracts_cluster[\"pctWhite\"] = NJ_tracts_cluster[\"WhiteAlone\"]/NJ_tracts_cluster[\"TotalPop\"]* 100\n\n# simplified cluster df\nNJ_cluster_data = NJ_tracts_cluster.loc[:, (\n    \"tractID\",\n    \"mean_amountbuildingDamageAmount\",\n    \"MedInc\",\n    \"pctWhite\",\n    \"TotalPop\",\n    \"observation\"\n)].dropna()\n\n\nThe variables of interest are scaled due to the differences in ranges between variables - doing so ensures that the variable with the largest values is not weighted more heavily in the cluster analysis. Additionally, the elbow method is used to derive the optimal number of clusters based on what appears to be the hinge of the curve - based on the chart, this inflection point appears to be five clusters. The k-means analysis is then run on the scaled data with five clusters set as the parameter\n\n\nCode\n# scales data for kmeans clustering\nclaims_scaled = scaler.fit_transform(\n    NJ_cluster_data[[\"mean_amountbuildingDamageAmount\",\n                     \"MedInc\",\n                     \"pctWhite\",\n                     \"TotalPop\",\n                     \"observation\"\n                    ]])\n\n# Number of clusters to try out\nn_clusters = list(range(2, 10))\n\n# Run kmeans for each value of k\ninertias = []\nfor k in n_clusters:\n    \n    # Initialize and run\n    kmeans = KMeans(n_clusters=k, random_state=22, n_init=10)\n    kmeans.fit(claims_scaled)\n    \n    # Save the \"inertia\"\n    inertias.append(kmeans.inertia_)\n    \n# Plots knee graph\nplt.plot(n_clusters, inertias, marker='o', ms=10, mfc='white', lw=4, mew=3);\n\n\n\n\n\n\n\nCode\n# runs kmeans with five clusters\nkmeans = KMeans(n_clusters=5, random_state=22, n_init=10)\n\n# fits to scaled data\nkmeans.fit(claims_scaled)\n\n# adds labels to starting df\nNJ_cluster_data['label'] = kmeans.labels_\n\n# adds cluster categories\ncluster_map = {0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E',}\nNJ_cluster_data['Cluster'] = NJ_cluster_data['label'].map(cluster_map)\n\n# groups by label\ncluster_size = NJ_cluster_data.groupby('label', as_index=False).size()\n\n\nThe cluster analysis sorted the 1166 Census tracts with NFIP claims during the analysis dates to find optimal clusters based on the included variables. While all clusters averaged at least 21 claims per tract, the cluster associated with label 3 was hit especially hard in this time period.\n\n\nCode\n# calculates means by label\ncluster_summary = NJ_cluster_data.groupby(\"label\", as_index=False)[\n    [\"mean_amountbuildingDamageAmount\",\n     \"MedInc\", \n     \"pctWhite\",\n     \"TotalPop\",\n     \"observation\"\n    ]].mean()\n\n# merges cluster size\ncluster_summary = cluster_summary.merge(cluster_size)\n\n# outputs chart of cluster results\ncluster_summary\n\n\n\n\n\n\n\n\n\nlabel\nmean_amountbuildingDamageAmount\nMedInc\npctWhite\nTotalPop\nobservation\nsize\n\n\n\n\n0\n0\n13431.15\n114530.75\n74.37\n6333.91\n20.97\n375\n\n\n1\n1\n67609.47\n84987.63\n81.07\n4271.48\n123.08\n97\n\n\n2\n2\n12782.96\n52600.81\n26.61\n4383.97\n23.97\n264\n\n\n3\n3\n50503.18\n80140.19\n92.62\n3539.89\n1408.04\n27\n\n\n4\n4\n16023.57\n80599.71\n77.91\n3484.60\n44.44\n403\n\n\n\n\n\n\n\n\n\nCode\n# Normalizes data\ncluster_summary_normalized = (cluster_summary - cluster_summary.min()) / (cluster_summary.max() - cluster_summary.min())\n\n#cluster_summary_normalized\n\n\nThese normalized results show the relative differences in categories across clusters to support interpretability.\n\n\nCode\n# remaps categories\ncluster_map = {0: 'A', .25: 'B', .50: 'C', .75: 'D', 1: 'E',}\ncluster_summary_normalized['cluster'] = cluster_summary_normalized['label'].map(cluster_map)\n\n# renames columns\ncluster_summary_normalized_final = cluster_summary_normalized.rename(columns={\n    \"mean_amountbuildingDamageAmount\": \"Bldg_Dmg\",\n    \"mean_buildingPropertyValue\" : \"Bldg_Val\",\n    \"MedInc\": \"MedHHInc\",\n    \"pctWhite\": \"PctWhite\",\n    \"observation\": \"Claims\",\n    \"cluster\" : \"Cluster\"\n}).drop(['label', 'size'], axis=1).sort_values(by='Cluster')\n\n# outputs chart of normalized cluster results\ncluster_summary_normalized_final\n\n\n\n\n\n\n\n\n\nBldg_Dmg\nMedHHInc\nPctWhite\nTotalPop\nClaims\nCluster\n\n\n\n\n0\n0.01\n1.00\n0.72\n1.00\n0.00\nA\n\n\n1\n1.00\n0.52\n0.83\n0.28\n0.07\nB\n\n\n2\n0.00\n0.00\n0.00\n0.32\n0.00\nC\n\n\n3\n0.69\n0.44\n1.00\n0.02\n1.00\nD\n\n\n4\n0.06\n0.45\n0.78\n0.00\n0.02\nE\n\n\n\n\n\n\n\nTo further aid in interpretability, normalized values of each cluster are plotted to compare across clusters.\nWhile there are several factors in each cluster, some high level generalizations can be made about the Census tracts in each cluster during the analysis period of 2015-2019:\n\nCluster A: Wealthy, Populous, Lower Impact Flooding\nCluster B: High Impact Flooding\nCluster C: Lower Income, Non-White, Lower Impact Flooding\nCluster D: Sparsely Populated, High Impact Flooding\nCluster E: Sparsely Populated, Low Impact Flooding\n\n\n\n\n\n\n\nImportant\n\n\n\nThe following map inconsistently renders to the website, but loads in a Jupyter notebook - investigating underlying issue.\n\n\n\n\nCode\n# creates clustered bar chart of normalized cluster results\nclustered_bar_plot = cluster_summary_normalized_final.hvplot.bar(\n    x='Cluster',\n    y=['Bldg_Dmg', 'MedHHInc', 'PctWhite', \"Claims\", \"TotalPop\"],\n    xlabel='Cluster Label',\n    ylabel='Normalized Average Values',\n    rot = 45,\n    title='Normalized Average Values by Cluster',\n    width=1200, height=400,\n    groupby=[],\n)\n\n# outputs bar plot\nclustered_bar_plot\n\n\n\n\n\n\n  \n\n\n\n\nTo identify if any spatial clusters of Blue Acres tracts were located within any of the features clusters of NFIP and ACS tracts, the results of the k-means clustering are added back to the spatial data.\n\n\nCode\n# Merges cluster results with original df\nNJ_cluster_data_join = NJ_cluster_data.merge(\n    NJ_tracts,\n    left_on=[\"tractID\"],\n    right_on=[\"GEOID\"]\n\n)\n\n# converts merged results to gdf\nNJ_cluster_data_join_map = gpd.GeoDataFrame(NJ_cluster_data_join, geometry=NJ_cluster_data_join['geometry']).to_crs(\"EPSG:4326\")\n\n\nThe Blue Acres spatial clusters are loaded in, and tracts idenfied in the k-means clustering are joined to identify matches.\nThe 10 spatial clusters are relatively evenly distrubuted across the k-means cluster groups\n\nTwo Blue Acres Spatial Clusters in Group A: Wealthy, Populous, Lower Impact Flooding\nTwo Blue Acres Spatial Clusters in Group B: High Impact Flooding\nOne Blue Acres Spatial Cluster in Group C: Lower Income, Non-White, Lower Impact Flooding\nTwo Blue Acres Spatial Clusters in Group D: Sparsely Populated, High Impact Flooding\nThree Blue Acres Spatial Cluster in Group E: Sparsely Populated, Low Impact Flooding\n\nGiven the differences in time span between the two clustering analyses (all Blue Acres properties since 1995 and only claims between 2010-2014), strong conclusions cannot be drawn from comparing the two. However, the results highlight that the Blue Acres Program appears to be active in supporting a range of communities based on the analysis variables across the state.\n\n\nCode\n# reads and preprocesses saved DBSCAN cluster file for Blue Acres\nBA_clusters = pd.read_csv(\"data/BA_clusters_tracts.csv\")\nBA_clusters['GEOID'] = BA_clusters['GEOID'].astype(str)\n\n# Converts DBSCAN results to gdf\nBA_clusters = gpd.GeoDataFrame(\n    BA_clusters,\n    geometry=gpd.points_from_xy(BA_clusters[\"x\"], BA_clusters[\"y\"]),\n    crs=\"EPSG:3424\",\n).to_crs(\"EPSG:4326\")\n\n# adds kmeans results to DBSCAN clusters data\nBA_cluster_label = BA_clusters.merge(\n    NJ_cluster_data_join, \n    left_on = \"GEOID\", \n    right_on = \"tractID\"\n).groupby(\"Cluster\").size().reset_index()\n\n# renames column\nBA_cluster_label = BA_cluster_label.rename(\n    columns={\n        0: \"Count\",\n    }\n)\n\nBA_cluster_label\n\n\n\n\n\n\n\n\n\nCluster\nCount\n\n\n\n\n0\nA\n2\n\n\n1\nB\n2\n\n\n2\nC\n1\n\n\n3\nD\n2\n\n\n4\nE\n3\n\n\n\n\n\n\n\nThe following map visualized the results of the k-means clustering analysis spatially along with points representing the Blue Acres spatial clusters.\n\n\nCode\n# map of BA cluster points\nBA_points_map = BA_clusters.hvplot(\n    geo=True, \n    color='#011627', \n    line_color=\"#011627\",\n    size=200,\n    hover_cols=[\"GEOID\", \"label\"]\n)\n\n# map of cluster rsults\ncluster_map = NJ_cluster_data_join_map.hvplot(\n    color=\"Cluster\", \n    line_color=\"Cluster\", \n    line_width=.5,\n    alpha=0.8,\n    xaxis=None,\n    yaxis=None,\n    geo=True,\n    hover_cols=\"tractID\"\n).opts(cmap=['#8ac926', '#ffca3a','#ff595e', '#1982c4', '#6a4c93'], frame_height=700)\n\n# combines and outputs map of both\ncombined = cluster_map * BA_points_map\ncombined.opts(toolbar=\"above\")\n\n\n\n\n\n\n  \n\n\n\n\nGiven the gaps in data, direct conclusions cannot be drawn from this analysis. The temporal aspect of the data and differing geographies across years at the more granular level present challenges for stronger results. However, the methods presented can provide powerful options for more in-depth research into NFIP claims and Blue Acres data moving forward and are worth refining over time for this analysis."
  },
  {
    "objectID": "analysis/ClaimsKmeans.html#nfip-k-means-clustering-and-blue-acres-spatial-cluster-overlay",
    "href": "analysis/ClaimsKmeans.html#nfip-k-means-clustering-and-blue-acres-spatial-cluster-overlay",
    "title": "4) Clustering by Features",
    "section": "",
    "text": "Using the NJ NFIP single family home claims data in conjunction with US Census Bureau American Community Survey (ACS) data, the k-means clustering analyis is used to identify tracts with similar features and label these clusters based on their similar characteristics.\n\n\nCode\n# packages\nimport geopandas as gpd\nimport holoviews as hv\nimport hvplot.pandas\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nimport cenpy\nimport pygris\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import MinMaxScaler, RobustScaler\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\n\n# options\npd.options.display.max_columns = 999\npd.options.display.max_rows = 999\npd.options.display.float_format = '{:.2f}'.format\n\n\nThis data comes from the NFIP redacted claims data set that was filtered for New Jersey, as descibed on the NFIP Data Processing page. New Jersey tracts boundaries are downloaded using the pygris package.\nBecause ACS 5-year estimates are used for economic and demographic characteristics and Census tract geography may change every 10 years when a new Census occurs, single family homes claims data is filtered to include claims between 2010 and 2014. This data was chosen due to the high number of claims that occured in time period from both Hurricane Irene and Hurricane Sandy while matching a range for the ACS 5-year estimates.\n\n\nCode\n# reads data and does preprocessing steps\nclaims_NJ = pd.read_csv(\"data/claims_sfh.csv\")\nclaims_NJ['countyCode'] = claims_NJ['countyCode'].astype(str).str.rstrip('.0')\nclaims_NJ['censusTract'] = claims_NJ['censusTract'].astype(str).str.rstrip('.0')\nclaims_NJ['censusBlockGroupFips'] = claims_NJ['censusBlockGroupFips'].astype(str).str.rstrip('.0')\nclaims_NJ['yearOfLoss'] = pd.to_datetime(claims_NJ['yearOfLoss'], format='%Y').dt.year\n\nclaims_NJ = claims_NJ[(claims_NJ['yearOfLoss'] &gt;= 2010) & (claims_NJ['yearOfLoss'] &lt;= 2014)] \n\n# download administrative boundaries for mapping from pygris\nNJ_tracts = pygris.tracts(state=\"NJ\", year=2014)\n\n\nClaims are aggregating per Census tracts using the average building damage amount and total property value, as well as the sum of total claims for the Census tract, then joined to the tract information from pygris.\n\n\nCode\n\n# helper functions for aggregating data\nagg_functions = {\n    'buildingDamageAmount': 'mean',\n    'observation': 'sum',\n}\n\n# groups by tract and uses helper functions\nclaims_by_tract = claims_NJ.groupby([\"censusTract\"]).agg(agg_functions).reset_index()\n\n# reduces df to necessary columns \nclaims_by_tract.columns = ['censusTract',\n                           'mean_amountbuildingDamageAmount',\n                           'observation']\n\n# fills in tracts with missing ending 0s (compared length to GEOID and naming conventions)\nclaims_by_tract['censusTract'] = claims_by_tract['censusTract'].astype(str).str.pad(width=11, side='right', fillchar='0')\n\n# joins claims to tracts data\nNJ_tracts_join = claims_by_tract.merge(\n    NJ_tracts,\n    left_on=[\"censusTract\"],\n    right_on=[\"GEOID\"]\n)\n\n\nThe Census API is accessed to acquire 5-year estimate data tied to 2014. Variables of interest include the total population of a tract, the number of residents that are white alone, and the median household income in the past 12 months. The population variables are used to calculate the percentage of white residents per Census tracts - the purpose of using this variable is to identify if there are any demographic trends to claims or areas with a high presence of Blue Acres parcels. The data is then added to a dataframe with claims data (average damage and property value for single family homes claims).\n\n\nCode\n# accesses API for ACS 5yr 2019\nacs = cenpy.remote.APIConnection(\"ACSDT5Y2014\")\n\n# defines variables of interest\nvariables = [\n    \"NAME\",\n    \"B03002_001E\", # Total\n    \"B03002_003E\", # Not Hispanic, White\n    \"B19013_001E\", # Median Household Income in Past 12 Months\n]\n\n# accesses API for Census\nNJ_acs = acs.query(\n    cols=variables,\n    geo_unit=\"tract:*\",\n    geo_filter={\"state\": \"34\", \"county\": \"*\"},\n)\n\n# Concats parts of GEOID\nNJ_acs['GEOID'] = NJ_acs['state'].astype(str) + NJ_acs['county'].astype(str) + NJ_acs['tract'].astype(str)\n\n# Converts values from strings to floats\nfor variable in variables:\n    # Convert all variables EXCEPT for NAME\n    if variable != \"NAME\":\n        NJ_acs[variable] = NJ_acs[variable].astype(float)\n        \n# joins tracts data with ACS data\nNJ_tracts_cluster = NJ_tracts_join.merge(\n    NJ_acs,\n    left_on=[\"censusTract\"],\n    right_on=[\"GEOID\"],\n)\n\n# Renames columns\nNJ_tracts_cluster = NJ_tracts_cluster.rename(\n    columns={\n        \"censusTract\" : \"tractID\",\n        \"B03002_001E\": \"TotalPop\", \n        \"B03002_003E\": \"WhiteAlone\",  \n        \"B19013_001E\": \"MedInc\",  \n    }\n)\n\n# Calculates percent of population that's white alone\nNJ_tracts_cluster[\"pctWhite\"] = NJ_tracts_cluster[\"WhiteAlone\"]/NJ_tracts_cluster[\"TotalPop\"]* 100\n\n# simplified cluster df\nNJ_cluster_data = NJ_tracts_cluster.loc[:, (\n    \"tractID\",\n    \"mean_amountbuildingDamageAmount\",\n    \"MedInc\",\n    \"pctWhite\",\n    \"TotalPop\",\n    \"observation\"\n)].dropna()\n\n\nThe variables of interest are scaled due to the differences in ranges between variables - doing so ensures that the variable with the largest values is not weighted more heavily in the cluster analysis. Additionally, the elbow method is used to derive the optimal number of clusters based on what appears to be the hinge of the curve - based on the chart, this inflection point appears to be five clusters. The k-means analysis is then run on the scaled data with five clusters set as the parameter\n\n\nCode\n# scales data for kmeans clustering\nclaims_scaled = scaler.fit_transform(\n    NJ_cluster_data[[\"mean_amountbuildingDamageAmount\",\n                     \"MedInc\",\n                     \"pctWhite\",\n                     \"TotalPop\",\n                     \"observation\"\n                    ]])\n\n# Number of clusters to try out\nn_clusters = list(range(2, 10))\n\n# Run kmeans for each value of k\ninertias = []\nfor k in n_clusters:\n    \n    # Initialize and run\n    kmeans = KMeans(n_clusters=k, random_state=22, n_init=10)\n    kmeans.fit(claims_scaled)\n    \n    # Save the \"inertia\"\n    inertias.append(kmeans.inertia_)\n    \n# Plots knee graph\nplt.plot(n_clusters, inertias, marker='o', ms=10, mfc='white', lw=4, mew=3);\n\n\n\n\n\n\n\nCode\n# runs kmeans with five clusters\nkmeans = KMeans(n_clusters=5, random_state=22, n_init=10)\n\n# fits to scaled data\nkmeans.fit(claims_scaled)\n\n# adds labels to starting df\nNJ_cluster_data['label'] = kmeans.labels_\n\n# adds cluster categories\ncluster_map = {0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E',}\nNJ_cluster_data['Cluster'] = NJ_cluster_data['label'].map(cluster_map)\n\n# groups by label\ncluster_size = NJ_cluster_data.groupby('label', as_index=False).size()\n\n\nThe cluster analysis sorted the 1166 Census tracts with NFIP claims during the analysis dates to find optimal clusters based on the included variables. While all clusters averaged at least 21 claims per tract, the cluster associated with label 3 was hit especially hard in this time period.\n\n\nCode\n# calculates means by label\ncluster_summary = NJ_cluster_data.groupby(\"label\", as_index=False)[\n    [\"mean_amountbuildingDamageAmount\",\n     \"MedInc\", \n     \"pctWhite\",\n     \"TotalPop\",\n     \"observation\"\n    ]].mean()\n\n# merges cluster size\ncluster_summary = cluster_summary.merge(cluster_size)\n\n# outputs chart of cluster results\ncluster_summary\n\n\n\n\n\n\n\n\n\nlabel\nmean_amountbuildingDamageAmount\nMedInc\npctWhite\nTotalPop\nobservation\nsize\n\n\n\n\n0\n0\n13431.15\n114530.75\n74.37\n6333.91\n20.97\n375\n\n\n1\n1\n67609.47\n84987.63\n81.07\n4271.48\n123.08\n97\n\n\n2\n2\n12782.96\n52600.81\n26.61\n4383.97\n23.97\n264\n\n\n3\n3\n50503.18\n80140.19\n92.62\n3539.89\n1408.04\n27\n\n\n4\n4\n16023.57\n80599.71\n77.91\n3484.60\n44.44\n403\n\n\n\n\n\n\n\n\n\nCode\n# Normalizes data\ncluster_summary_normalized = (cluster_summary - cluster_summary.min()) / (cluster_summary.max() - cluster_summary.min())\n\n#cluster_summary_normalized\n\n\nThese normalized results show the relative differences in categories across clusters to support interpretability.\n\n\nCode\n# remaps categories\ncluster_map = {0: 'A', .25: 'B', .50: 'C', .75: 'D', 1: 'E',}\ncluster_summary_normalized['cluster'] = cluster_summary_normalized['label'].map(cluster_map)\n\n# renames columns\ncluster_summary_normalized_final = cluster_summary_normalized.rename(columns={\n    \"mean_amountbuildingDamageAmount\": \"Bldg_Dmg\",\n    \"mean_buildingPropertyValue\" : \"Bldg_Val\",\n    \"MedInc\": \"MedHHInc\",\n    \"pctWhite\": \"PctWhite\",\n    \"observation\": \"Claims\",\n    \"cluster\" : \"Cluster\"\n}).drop(['label', 'size'], axis=1).sort_values(by='Cluster')\n\n# outputs chart of normalized cluster results\ncluster_summary_normalized_final\n\n\n\n\n\n\n\n\n\nBldg_Dmg\nMedHHInc\nPctWhite\nTotalPop\nClaims\nCluster\n\n\n\n\n0\n0.01\n1.00\n0.72\n1.00\n0.00\nA\n\n\n1\n1.00\n0.52\n0.83\n0.28\n0.07\nB\n\n\n2\n0.00\n0.00\n0.00\n0.32\n0.00\nC\n\n\n3\n0.69\n0.44\n1.00\n0.02\n1.00\nD\n\n\n4\n0.06\n0.45\n0.78\n0.00\n0.02\nE\n\n\n\n\n\n\n\nTo further aid in interpretability, normalized values of each cluster are plotted to compare across clusters.\nWhile there are several factors in each cluster, some high level generalizations can be made about the Census tracts in each cluster during the analysis period of 2015-2019:\n\nCluster A: Wealthy, Populous, Lower Impact Flooding\nCluster B: High Impact Flooding\nCluster C: Lower Income, Non-White, Lower Impact Flooding\nCluster D: Sparsely Populated, High Impact Flooding\nCluster E: Sparsely Populated, Low Impact Flooding\n\n\n\n\n\n\n\nImportant\n\n\n\nThe following map inconsistently renders to the website, but loads in a Jupyter notebook - investigating underlying issue.\n\n\n\n\nCode\n# creates clustered bar chart of normalized cluster results\nclustered_bar_plot = cluster_summary_normalized_final.hvplot.bar(\n    x='Cluster',\n    y=['Bldg_Dmg', 'MedHHInc', 'PctWhite', \"Claims\", \"TotalPop\"],\n    xlabel='Cluster Label',\n    ylabel='Normalized Average Values',\n    rot = 45,\n    title='Normalized Average Values by Cluster',\n    width=1200, height=400,\n    groupby=[],\n)\n\n# outputs bar plot\nclustered_bar_plot\n\n\n\n\n\n\n  \n\n\n\n\nTo identify if any spatial clusters of Blue Acres tracts were located within any of the features clusters of NFIP and ACS tracts, the results of the k-means clustering are added back to the spatial data.\n\n\nCode\n# Merges cluster results with original df\nNJ_cluster_data_join = NJ_cluster_data.merge(\n    NJ_tracts,\n    left_on=[\"tractID\"],\n    right_on=[\"GEOID\"]\n\n)\n\n# converts merged results to gdf\nNJ_cluster_data_join_map = gpd.GeoDataFrame(NJ_cluster_data_join, geometry=NJ_cluster_data_join['geometry']).to_crs(\"EPSG:4326\")\n\n\nThe Blue Acres spatial clusters are loaded in, and tracts idenfied in the k-means clustering are joined to identify matches.\nThe 10 spatial clusters are relatively evenly distrubuted across the k-means cluster groups\n\nTwo Blue Acres Spatial Clusters in Group A: Wealthy, Populous, Lower Impact Flooding\nTwo Blue Acres Spatial Clusters in Group B: High Impact Flooding\nOne Blue Acres Spatial Cluster in Group C: Lower Income, Non-White, Lower Impact Flooding\nTwo Blue Acres Spatial Clusters in Group D: Sparsely Populated, High Impact Flooding\nThree Blue Acres Spatial Cluster in Group E: Sparsely Populated, Low Impact Flooding\n\nGiven the differences in time span between the two clustering analyses (all Blue Acres properties since 1995 and only claims between 2010-2014), strong conclusions cannot be drawn from comparing the two. However, the results highlight that the Blue Acres Program appears to be active in supporting a range of communities based on the analysis variables across the state.\n\n\nCode\n# reads and preprocesses saved DBSCAN cluster file for Blue Acres\nBA_clusters = pd.read_csv(\"data/BA_clusters_tracts.csv\")\nBA_clusters['GEOID'] = BA_clusters['GEOID'].astype(str)\n\n# Converts DBSCAN results to gdf\nBA_clusters = gpd.GeoDataFrame(\n    BA_clusters,\n    geometry=gpd.points_from_xy(BA_clusters[\"x\"], BA_clusters[\"y\"]),\n    crs=\"EPSG:3424\",\n).to_crs(\"EPSG:4326\")\n\n# adds kmeans results to DBSCAN clusters data\nBA_cluster_label = BA_clusters.merge(\n    NJ_cluster_data_join, \n    left_on = \"GEOID\", \n    right_on = \"tractID\"\n).groupby(\"Cluster\").size().reset_index()\n\n# renames column\nBA_cluster_label = BA_cluster_label.rename(\n    columns={\n        0: \"Count\",\n    }\n)\n\nBA_cluster_label\n\n\n\n\n\n\n\n\n\nCluster\nCount\n\n\n\n\n0\nA\n2\n\n\n1\nB\n2\n\n\n2\nC\n1\n\n\n3\nD\n2\n\n\n4\nE\n3\n\n\n\n\n\n\n\nThe following map visualized the results of the k-means clustering analysis spatially along with points representing the Blue Acres spatial clusters.\n\n\nCode\n# map of BA cluster points\nBA_points_map = BA_clusters.hvplot(\n    geo=True, \n    color='#011627', \n    line_color=\"#011627\",\n    size=200,\n    hover_cols=[\"GEOID\", \"label\"]\n)\n\n# map of cluster rsults\ncluster_map = NJ_cluster_data_join_map.hvplot(\n    color=\"Cluster\", \n    line_color=\"Cluster\", \n    line_width=.5,\n    alpha=0.8,\n    xaxis=None,\n    yaxis=None,\n    geo=True,\n    hover_cols=\"tractID\"\n).opts(cmap=['#8ac926', '#ffca3a','#ff595e', '#1982c4', '#6a4c93'], frame_height=700)\n\n# combines and outputs map of both\ncombined = cluster_map * BA_points_map\ncombined.opts(toolbar=\"above\")\n\n\n\n\n\n\n  \n\n\n\n\nGiven the gaps in data, direct conclusions cannot be drawn from this analysis. The temporal aspect of the data and differing geographies across years at the more granular level present challenges for stronger results. However, the methods presented can provide powerful options for more in-depth research into NFIP claims and Blue Acres data moving forward and are worth refining over time for this analysis."
  },
  {
    "objectID": "analysis/BlueAcres.html",
    "href": "analysis/BlueAcres.html",
    "title": "1) Blue Acres Program",
    "section": "",
    "text": "The New Jersey Blue Acres Program is a state-run program that supports relocating homeowners away from flood-prone properties and redeveloping the land to encourage climate resiliency. Operating since 1995, the NJ Department of Environmental Protection (DEP) leads Blue Acres program and coordinates with homeowners, local governments, and the federal government, ultimately connecting federal funds with at-risk properties and guiding the homeowners through the process of selling their home to the state. Once a home is purchased following a successful application and buyout process, the property is demolished and rehabilitated into a flood-resilient space - open space that can act as natural flood storage or protection in a flooding event. Blue Acres staff also work closely with municipalities to support climate resilience planning through the program’s buyout process and coordinate long-term stewardship of the community space.\n\n\nThe Blue Acres website defines two core missions of the program:\n\nDisaster Recovery\n\nBlue Acres helps New Jersey residents whose homes have been damaged in flooding events, such as those whose homes were destroyed or damaged when the remnants of Tropical Storm Ida impacted New Jersey in September 2021.\n\nPreparedness:\n\nBlue Acres contributes to New Jersey’s Climate Change Resilience Strategy through a proactive approach to guide state acquisition of lands that increases host community resilience through the strategic acquisition of lands that have been damaged, or may be prone to future damage, due to sea-level rise, storms, or storm-related flooding, or that may buffer or protect other lands from such damage.\n\n\n\n\n\nFunding for the program comes from a mixture of federal and state dollars. Much of the funding comes from the Federal Emergency Management Agency (FEMA), which is also one of the major partners of the program. Blue Acres has received funding from federal sources such as 1 :\n\nFEMA’s Hazard Mitigation Grant Program (HMGP)\nUS Department of Housing and Urban Development’s Community Development Block Grant – Disaster Recovery program\nUS Department of Agriculture – Natural Resources Conservation Service\n\nAdditionally, the state contributes funding - residents have previously passed bonds to provide funding for property acquisitions and in 2019, a constitutional amendment was passed to provide funding for the program from a portion of the state corporate business tax. 2 A large influx of funding came in response to Hurricane Sandy in 2012, which caused billions of dollars in damage in New Jersey.\n\n\n\nSince the program began in 1995, over 1,400 properties have been acquired. While this number is low, the program is nationally recognized for its ability to both help homeowners navigate the difficult process of a state-led buyout to relocate and convert former flood-prone properties to more sustainable flood-resilient spaces. However, a DEP-funded study by researchers at Rutgers University and South Dakota State University highlighted how about 630,000 properties in the state “greater than a 26% chance of being severely affected by flooding over the next 30 years” which is compounded by the state being the most densely populated and thus highly developed in terms of land use in the country. 3\n\n\n\nThe Blue Acres website provides some guidance on eligibility and criteria for a homeowner to receive funding for a buyout, but states that the program evaluates property based on a range of information. All buyouts are voluntary, and there is no requirement for nearby and contiguous properties in the neighborhood to also be purchased in order for a homeowner to receive a buyout. The Frequently Asked Questions page of their website states the following as considerations, although they state that this list is not exhaustive:\n\nCommunities with high risk and vulnerability to climate change.\nEnvironmental justice or overburdened communities that are disproportionately impacted by flooding and other adverse environmental conditions.\nA high concentration of homes that experienced the most severe damage from a recent storm especially when several homes resulted in an official declaration of substantial damage.\nCommunities with homes that have submitted repeated flood insurance claims under the National Flood Insurance Program.\nResilience interest and buyout support from the local government.\nCost-effectiveness of the buyout according to FEMA requirements under federal law.\nOpportunity for significant environmental impact and/or improvement to public health, safety and welfare.\n\nAdditionally, the FAQ notes that nearly all costs are covered by Blue Acres, including aspects such as the appraisal, any land reviews, the actual purchase, and demolition. A separate webpage discusses the role of local government, who can request what properties are eligible for a buyout if they are in a flood-prone area."
  },
  {
    "objectID": "analysis/BlueAcres.html#program-overview",
    "href": "analysis/BlueAcres.html#program-overview",
    "title": "1) Blue Acres Program",
    "section": "",
    "text": "The New Jersey Blue Acres Program is a state-run program that supports relocating homeowners away from flood-prone properties and redeveloping the land to encourage climate resiliency. Operating since 1995, the NJ Department of Environmental Protection (DEP) leads Blue Acres program and coordinates with homeowners, local governments, and the federal government, ultimately connecting federal funds with at-risk properties and guiding the homeowners through the process of selling their home to the state. Once a home is purchased following a successful application and buyout process, the property is demolished and rehabilitated into a flood-resilient space - open space that can act as natural flood storage or protection in a flooding event. Blue Acres staff also work closely with municipalities to support climate resilience planning through the program’s buyout process and coordinate long-term stewardship of the community space.\n\n\nThe Blue Acres website defines two core missions of the program:\n\nDisaster Recovery\n\nBlue Acres helps New Jersey residents whose homes have been damaged in flooding events, such as those whose homes were destroyed or damaged when the remnants of Tropical Storm Ida impacted New Jersey in September 2021.\n\nPreparedness:\n\nBlue Acres contributes to New Jersey’s Climate Change Resilience Strategy through a proactive approach to guide state acquisition of lands that increases host community resilience through the strategic acquisition of lands that have been damaged, or may be prone to future damage, due to sea-level rise, storms, or storm-related flooding, or that may buffer or protect other lands from such damage.\n\n\n\n\n\nFunding for the program comes from a mixture of federal and state dollars. Much of the funding comes from the Federal Emergency Management Agency (FEMA), which is also one of the major partners of the program. Blue Acres has received funding from federal sources such as 1 :\n\nFEMA’s Hazard Mitigation Grant Program (HMGP)\nUS Department of Housing and Urban Development’s Community Development Block Grant – Disaster Recovery program\nUS Department of Agriculture – Natural Resources Conservation Service\n\nAdditionally, the state contributes funding - residents have previously passed bonds to provide funding for property acquisitions and in 2019, a constitutional amendment was passed to provide funding for the program from a portion of the state corporate business tax. 2 A large influx of funding came in response to Hurricane Sandy in 2012, which caused billions of dollars in damage in New Jersey.\n\n\n\nSince the program began in 1995, over 1,400 properties have been acquired. While this number is low, the program is nationally recognized for its ability to both help homeowners navigate the difficult process of a state-led buyout to relocate and convert former flood-prone properties to more sustainable flood-resilient spaces. However, a DEP-funded study by researchers at Rutgers University and South Dakota State University highlighted how about 630,000 properties in the state “greater than a 26% chance of being severely affected by flooding over the next 30 years” which is compounded by the state being the most densely populated and thus highly developed in terms of land use in the country. 3\n\n\n\nThe Blue Acres website provides some guidance on eligibility and criteria for a homeowner to receive funding for a buyout, but states that the program evaluates property based on a range of information. All buyouts are voluntary, and there is no requirement for nearby and contiguous properties in the neighborhood to also be purchased in order for a homeowner to receive a buyout. The Frequently Asked Questions page of their website states the following as considerations, although they state that this list is not exhaustive:\n\nCommunities with high risk and vulnerability to climate change.\nEnvironmental justice or overburdened communities that are disproportionately impacted by flooding and other adverse environmental conditions.\nA high concentration of homes that experienced the most severe damage from a recent storm especially when several homes resulted in an official declaration of substantial damage.\nCommunities with homes that have submitted repeated flood insurance claims under the National Flood Insurance Program.\nResilience interest and buyout support from the local government.\nCost-effectiveness of the buyout according to FEMA requirements under federal law.\nOpportunity for significant environmental impact and/or improvement to public health, safety and welfare.\n\nAdditionally, the FAQ notes that nearly all costs are covered by Blue Acres, including aspects such as the appraisal, any land reviews, the actual purchase, and demolition. A separate webpage discusses the role of local government, who can request what properties are eligible for a buyout if they are in a flood-prone area."
  },
  {
    "objectID": "analysis/BlueAcres.html#data-exploration-and-analysis",
    "href": "analysis/BlueAcres.html#data-exploration-and-analysis",
    "title": "1) Blue Acres Program",
    "section": "Data Exploration and Analysis",
    "text": "Data Exploration and Analysis\nThe Blue Acres website provides little detail regarding where these buyouts have occurred and what areas that the DEP considers for its mission of proactive climate reslience planning for flood-prone areas. The website, as well as external sources, generally do not include mapping or summaries of the impact of the program statewide However, publicly available parcel records accessed through the NJDEP’s Bureau of GIS can help identify and visualize implementation of the Blue Acres program.\n\n\nCode\n# packages\nimport geopandas as gpd\nimport holoviews as hv\nimport hvplot.pandas\nimport numpy as np\nimport pandas as pd\nimport cenpy\nimport pygris\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nfrom sklearn.cluster import dbscan \nimport datetime as dt\nfrom pyproj import CRS\nimport requests\n\n# options\npd.options.display.max_columns = 999\npd.options.display.max_rows = 999\npd.options.display.float_format = '{:.2f}'.format\n\n\n\nMapping Blue Acres-Funded Parcels\nNJDEP Bureau of GIS provides API access to their data sets - this analysis uses the data set titled State, Local and Nonprofit Open Space of New Jersey. This data is accessed and filtered to include only parcels that are designated with “Blue Acres Program” as their funding type - 1,436 as of December 2023.\nAdditionally, the pygris Python package is used to download administrative boundaries for both New Jersey counties and Census tracts - 2019 boundaries are used for consistency with time periods used in the k-means clustering analysis conducted at a later stage in this project.\n\n\nCode\n# downloads Blue Acres parcels from NJDEP API\nurl = \"https://mapsdep.nj.gov/arcgis/rest/services/Features/Land/MapServer/65/query\"\nparams = {\n    \"where\": \"FUNDING_TYPE = 'Blue Acres Program'\",  # Give me all rows\n    \"outFields\": \"*\",  # All fields\n    \"f\": \"geojson\",  # GeoJSON format\n    \"outSR\": \"4326\",  # The desired output CRS\n}\nr = requests.get(url, params=params)\njson = r.json()\nfeatures = json[\"features\"]\n\n# saves to gdf\nblueAcres = gpd.GeoDataFrame.from_features(features, crs=\"EPSG:4326\")\n\n# gets centroids and associated coordinates from parcels\nblueAcres['centroid'] = blueAcres['geometry'].to_crs(\"EPSG:3424\").centroid\nblueAcres['x'] = blueAcres['centroid'].x\nblueAcres['y'] = blueAcres['centroid'].y\n\n# download administrative boundaries for mapping from pygris\nNJ_counties = pygris.counties(state=\"NJ\", year=2019).to_crs(\"EPSG:3424\")\nNJ_tracts = pygris.tracts(state=\"NJ\", year=2019).to_crs(\"EPSG:3424\")\n\n#blueAcres.count()\n\n\nOnce downloaded, a simple interactive map of Blue Acres parcels allows users to view where buyouts have occured across the state since the program was implemented in 1995.\n\n\nCode\n# exploratory map of BA parcels\nblueAcres.explore(tiles=\"Cartodb positron\",\n                  style_kwds={\n                      \"weight\": 3,\n                      \"color\": \"darkblue\",\n                  },\n                  highlight=True,\n                  highlight_kwds={\n                      \"weight\": 10,\n                      \"color\": \"lightblue\",\n                  },\n                  tooltip = [\"COUNTY\", \"MUNICIPALITY\", \"PAMS_PIN\", \"GISACRES\"],\n                  height = 600\n                 )\n\n\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\n\n\nComparing Buyouts Across Towns and Counties\nThe NJDEP data includes fields for the municipality and county where the parcel is located. After creating two groupings of this data by those two location parameters and finding the size of each group, charts can be generated that show what municipalities or counties have seen the most purchases by the Blue Acres program.\nManville Borough in Somerset County, the muncipality with highest number of properties has experienced repetitive and severe flooding including Hurricane Irene in 2011, Hurricane Sandy in 2012, and Hurricane Ida.\nSayreville, Woodbridge, and South River are all in Middlesex County and were especially damaged by Hurricane Sandy.\nLincoln Park is in Morris County and has been consistently flooded due in part to over two-thirds of the community presiding in a FEMA Special Flood Hazard Area (1% annual flood chance) - the borough also had significant damage from Hurricane Irene. 4\n\n\nCode\n#groups observations by municipality and county\ncount1 = blueAcres.groupby([\"MUNICIPALITY\"]).size().sort_values(ascending=False).reset_index().rename(columns={0: 'COUNT'})\ncount2 = blueAcres.groupby([\"COUNTY\"]).size().sort_values(ascending=False).reset_index().rename(columns={0: 'COUNT'})\n\nf, ax= plt.subplots(1, 2, figsize=(10, 6))\n\n# Plot for MUNICIPALITY\nsns.barplot(\n    x='COUNT', \n    y='MUNICIPALITY', \n    data=count1,\n    color=\"darkblue\",\n    ax=ax[0]  # Use the first subplot\n)\n\n# Plot for COUNTY\nsns.barplot(\n    x='COUNT', \n    y='COUNTY', \n    data=count2,\n    color=\"lightblue\",\n    ax=ax[1]  # Use the second subplot\n)\n\n# Customize plot aesthetics\nax[0].set_title('Properties Purchased by Municipality')\nax[0].set_xlabel('Count')\nax[0].set_ylabel('Municipality')\n\nax[1].set_title('Properties Purchased by County')\nax[1].set_xlabel('Count')\nax[1].set_ylabel('County')\n\n# Adjust layout to prevent clipping of titles\nplt.tight_layout()\n\n\n\n\n\n\n\nBlue Acres Parcel Cluster Analysis\nThrough the clustering algorithm DBSCAN (Density-Based Spatial Clustering of Applications with Noise), areas with significant numbers of buyouts can be identified. Parcels are converted to points using their centroid and parameters are set - for this analysis, the maximum distance between two points to be considered as in the same neighborhood is 2 miles, and there must be 49 neighboring points for an individual point to be considered a part of the core cluster. Points within two miles but without 49 neighboring points, are still considered a part of the cluster, but are considered edge points. Points outside of two miles are considered “noise points”.\nThe algorithm with these parameters determined that only 119 points were noise points - over 1,300 points were included in one of 10 clusters of Blue Acres parcels.\n\n\nCode\nblueAcres_dbscan = blueAcres[[\"x\", \"y\", \"centroid\"]]\n\n# dbscan parameters\neps = 10560  # in feet (2 miles)\nmin_samples = 30\n\ncores, labels = dbscan(blueAcres_dbscan[[\"x\", \"y\"]], eps=eps, min_samples=min_samples)\n\nnum_cores = len(cores)\nblueAcres_dbscan['label'] = labels\nnum_clusters = blueAcres_dbscan['label'].nunique() - 1\n\ncluster_sizes = blueAcres_dbscan.groupby('label', as_index=False).size()\n\nnum_noise = cluster_sizes.iloc[0]['size']\n\nprint(f\"number of noise points = {num_noise}\")\n\n\nnumber of noise points = 119\n\n\nThe following maps shows individual Blue Acres properties in blue on the left and the average location of the DBSCAN-identified clusters in orange on the right, with noise points in blue. These maps show that a majority of clusters are inland, with flooding most likely to have occured from riverine flooding. There are also several clusters near the coast of central New Jersey, where Sayreville, Woodbridge, and South River are located.\n\n\nCode\n# Plots points of parcels and clusters side by side\nf, ax = plt.subplots(1, 2, figsize=(10, 10))\n\nNJ_counties.plot(ax=ax[0], \n               color = \"lightblue\", \n               edgecolor=\"white\",\n               linewidth = 2,)\nblueAcres['centroid'].plot(ax=ax[0], \n                           color='darkblue', \n                           markersize=1)\n\nax[0].set_title('Blue Acres Purchased Properties', color = \"darkblue\")\nax[0].set_axis_off()\n\nNJ_counties.plot(ax=ax[1], \n               color = \"lightblue\", \n               edgecolor=\"white\",\n               linewidth = 2,)\nnoise = blueAcres_dbscan.loc[blueAcres_dbscan[\"label\"] == -1]\nax[1].scatter(noise[\"x\"], noise[\"y\"], c=\"darkblue\", s=5, linewidth=0)\n\nfor label_num in range(0, num_clusters):\n\n    this_cluster = blueAcres_dbscan.loc[blueAcres_dbscan[\"label\"] == label_num]\n\n    x_mean = this_cluster[\"x\"].mean()\n    y_mean = this_cluster[\"y\"].mean()\n    \n    ax[1].scatter(x_mean, y_mean, linewidth=0, color=\"darkorange\")\n\nax[1].set_title('Clusters of Blue Acres Properties', color='darkorange')\nax[1].set_axis_off()\n\n\n\n\n\nThe average locations of these clusters are then merged with Census tract data from pygris and saved to a separate file for use in the the k-means clustering analysis at a later stage in this project.\n\n\nCode\n# Chunk for extracting and saving file for cluster points to use with NFIP data\ncluster_centroids = []\n\nfor label_num in range(0, num_clusters):\n\n    # Extract the samples with this label number\n    this_cluster = blueAcres_dbscan.loc[blueAcres_dbscan[\"label\"] == label_num]\n\n    # Calculate the mean (x,y) point for this cluster in red\n    x_mean = this_cluster[\"x\"].mean()\n    y_mean = this_cluster[\"y\"].mean()\n    \n    cluster_centroids.append((x_mean, y_mean, label_num))\n\ncluster_df = pd.DataFrame(cluster_centroids)\ncluster_df = cluster_df.rename(\n    columns={\n        0: \"x\",\n        1: \"y\",\n        2: \"label\"\n    }\n)\n\ncluster_gdf = gpd.GeoDataFrame(\n    cluster_df,\n    geometry=gpd.points_from_xy(cluster_df[\"x\"], cluster_df[\"y\"]),\n    crs=\"EPSG:3424\",\n)\n\ncluster_tracts = gpd.sjoin(NJ_tracts,cluster_gdf, how = \"inner\")\n\n# from pathlib import Path  \n\n# filepath = Path('data/BA_clusters_tracts.csv')  \n\n# filepath.parent.mkdir(parents=True, exist_ok=True)  \n\n# cluster_tracts.to_csv(filepath) \n\n\n\n\nCode\n# # accesses API for ACS 5yr 2019\n# acs = cenpy.remote.APIConnection(\"ACSDT5Y2019\")\n\n# # defines variables of interest\n# variables = [\n#     \"NAME\",\n#     \"B03002_001E\", # Total\n#     \"B03002_003E\", # Not Hispanic, White\n#     \"B19013_001E\", # Median Household Income in Past 12 Months\n# ]\n\n# # accesses API for Census\n# NJ_acs = acs.query(\n#     cols=variables,\n#     geo_unit=\"tract:*\",\n#     geo_filter={\"state\": \"34\", \"county\": \"*\"},\n# )\n\n# # Concats parts of GEOID\n# NJ_acs['GEOID'] = NJ_acs['state'].astype(str) + NJ_acs['county'].astype(str) + NJ_acs['tract'].astype(str)\n\n# # Converts values from strings to floats\n# for variable in variables:\n#     # Convert all variables EXCEPT for NAME\n#     if variable != \"NAME\":\n#         NJ_acs[variable] = NJ_acs[variable].astype(float)\n\n# # joins tracts data with ACS data\n# BA_ACS = cluster_tracts.merge(\n#     NJ_acs,\n#     left_on=[\"GEOID\"],\n#     right_on=[\"GEOID\"],\n# )\n\n# # Renames columns\n# BA_ACS = BA_ACS.rename(\n#     columns={\n#         \"censusTract\" : \"tractID\",\n#         \"B03002_001E\": \"TotalPop\", \n#         \"B03002_003E\": \"WhiteAlone\",  \n#         \"B19013_001E\": \"MedInc\",  \n#     }\n# )\n\n# # Calculates percent of population that's white alone\n# BA_ACS[\"pctWhite\"] = BA_ACS[\"WhiteAlone\"]/BA_ACS[\"TotalPop\"]* 100\n\n\n# # simplified cluster df\n# BA_ACS_simplified = BA_ACS.loc[:, (\n#     \"MedInc\",\n#     \"pctWhite\",\n#     \"TotalPop\",\n# )].dropna()\n\n# BA_ACS_simplified\n# BA_ACS_simplified.mean().reset_index().rename(\n#     columns={\n#         0 : \"Average\",\n#         \"index\" : \"Variable\"\n#     }\n# )\n\n\n\n\n\n\n\n\n\nMedInc\npctWhite\nTotalPop\n\n\n\n\n0\n76696.00\n64.76\n4824.00\n\n\n1\n55134.00\n30.59\n5047.00\n\n\n2\n73750.00\n65.83\n3123.00\n\n\n3\n124028.00\n58.76\n5453.00\n\n\n4\n90078.00\n66.38\n7760.00\n\n\n5\n115972.00\n75.05\n4137.00\n\n\n6\n77981.00\n72.99\n3761.00\n\n\n7\n67891.00\n86.76\n3663.00\n\n\n8\n86065.00\n62.60\n6534.00\n\n\n9\n84028.00\n34.06\n3541.00"
  },
  {
    "objectID": "analysis/DataCleaning.html",
    "href": "analysis/DataCleaning.html",
    "title": "2) NFIP Data Processing",
    "section": "",
    "text": "FEMA administers the National Flood Insurance Program (NFIP), which helps to identify flood risks, support floodplain management, and provide flood insurance and protection. The OpenFEMA data portal provides access to an Federal Insurance and Mitigation Administration (FIMA) NFIP Redacted Claims data set. This data set has over 2 million records, with personally identifying information removed and latitude/longitude coordinates simplified to one decimal. Due to challenges with accessing the data through FEMA’s API and being unable to host the file on GitHub due to file size, the data was instead downloaded locally, cleaned, and resaved to a smaller version available in this projects repository.\nCleaning steps included extracting latituden and longitude coordinates, then filtering for New Jersey claims between 1995 and 2023, with the latter date chosen since it aligns with the start of the Blue Acres program. Additionally, only single family home claims were included in this cleaned data set, since only private property is eligble for buyouts and the Blue Acres program has focused on homeowners.\n\n\nCode\n# packages\nimport geopandas as gpd\nimport numpy as np\nimport pandas as pd\n\n# options\npd.options.display.max_columns = 999\n\n# load data (not available in repo, file too large - download here: https://www.fema.gov/openfema-data-page/fima-nfip-redacted-claims-v2 \nclaims_df = pd.read_csv(\"data/claims.csv\")\n\nclaims_features= claims_df.loc[:, (\"dateOfLoss\", \n                          \"baseFloodElevation\", \n                          \"ratedFloodZone\", \n                          \"locationOfContents\", \n                          \"occupancyType\", \n                          \"amountPaidOnBuildingClaim\",\n                          \"amountPaidOnContentsClaim\",\n                          \"totalBuildingInsuranceCoverage\",\n                          \"totalContentsInsuranceCoverage\",\n                          \"yearOfLoss\",\n                          \"primaryResidenceIndicator\",\n                          \"buildingDamageAmount\", \n                          \"netBuildingPaymentAmount\",\n                          \"buildingPropertyValue\",\n                          \"contentsDamageAmount\",\n                          \"netContentsPaymentAmount\",\n                          \"contentsPropertyValue\",\n                          \"floodCharacteristicsIndicator\",\n                          \"floodWaterDuration\",\n                          \"floodproofedIndicator\",\n                          \"floodEvent\",\n                          \"buildingReplacementCost\",\n                          \"contentsReplacementCost\",\n                          \"stateOwnedIndicator\",\n                          \"buildingDescriptionCode\",\n                          \"rentalPropertyIndicator\",\n                          \"state\",\n                          \"countyCode\",\n                          \"censusTract\",\n                          \"censusBlockGroupFips\",\n                          \"latitude\",\n                          \"longitude\",\n                          \"id\")]\n\n# fix number formatting, have to repeat again when loading into a different notebook\nclaims_features['countyCode'] = claims_features['countyCode'].astype(str).str.rstrip('.0')\nclaims_features['censusTract'] = claims_features['censusTract'].astype(str).str.rstrip('.0')\nclaims_features['censusBlockGroupFips'] = claims_features['censusBlockGroupFips'].astype(str).str.rstrip('.0')\n\n# Remove rows with missing geometry\nclaims_features = claims_features.dropna(subset=[\"latitude\", \"longitude\"])\n\n# Create geoDataFrame\nclaims = gpd.GeoDataFrame(\n    claims_features,\n    geometry=gpd.points_from_xy(claims_df[\"longitude\"], claims_df[\"latitude\"]),\n    crs=\"EPSG:4326\",\n)\n\n# projected coordinate\nclaims_gpd = claims.to_crs('EPSG:3857')\n\n# extract lat and lon\nclaims_gpd['x'] = claims_gpd['geometry'].x\nclaims_gpd['y'] = claims_gpd['geometry'].y\n\n# filtering for NJ claims since 1995\nstates = ['NJ']\nclaims_NJ = claims_gpd[(claims_gpd['yearOfLoss'] &gt;= 1995) & (claims_gpd['state'].isin(states))]\n\n# save all NJ claims\nfrom pathlib import Path  \nfilepath = Path('data/claims_NJ.csv')  \nfilepath.parent.mkdir(parents=True, exist_ok=True)  \nclaims_NJ.to_csv(filepath) \n\n# cleaned claims add sfh parameter, claims_sfh creates separate df for them\nclaims_NJ_clean=claims_NJ\nsfh = (claims_NJ_clean['occupancyType'] == 1) | (claims_NJ_clean['occupancyType'] == 11)\nclaims_NJ_clean['sfh'] = np.where(sfh, 1, 0)\nclaims_NJ_clean['observation'] = 1\nclaims_sfh = claims_NJ_clean[claims_NJ_clean['sfh'] == 1]\n\n# save cleaned NJ claims\nfrom pathlib import Path  \nfilepath = Path('data/claims_NJ_clean.csv')  \nfilepath.parent.mkdir(parents=True, exist_ok=True)  \nclaims_NJ_clean.to_csv(filepath) \n\n# save single family housing NJ claims\nfrom pathlib import Path  \nfilepath = Path('data/claims_sfh.csv')  \nfilepath.parent.mkdir(parents=True, exist_ok=True)  \nclaims_sfh.to_csv(filepath)"
  },
  {
    "objectID": "analysis/index.html",
    "href": "analysis/index.html",
    "title": "Analysis",
    "section": "",
    "text": "Analysis\nData analysis for this project was conducted using Python through Jupyter notebooks. Analysis includes exploratory mapping, comparison plots, and clustering using both k-means and DBSCAN. Pages are meant to be read in the order they appear."
  }
]